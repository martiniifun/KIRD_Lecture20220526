{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 개요\n",
    "\n",
    "\"자연어처리\"는, \"컴퓨터가 인간의 언어를 알아들을 수 있게 만드는 학문\"입니다.\n",
    "\n",
    "과연 컴퓨터가 인간의 언어를 알아들을 수 있을까요? 2022년 현재 구글과 페이스북, 그리고 각종 대학교와 연구논문의 결과를 보고 있노라면 꿈만 같던 일이 이뤄지고 있는 것 같습니다. 특히 구글이 최근 개발하고 있는 언어모델 AI인 LaMDA(Language Model for Dialog Application) 이슈를 보면 AI가 지각을 가진 것 같은(?) 느낌이 들 정도로 발전했고요.\n",
    "\n",
    "https://www.mk.co.kr/news/world/view/2022/06/516140/\n",
    "\n",
    "하지만 모든 최첨단 기술에는 시작이 있는 법. 컴퓨팅 기술과 데이터 가용성이 향상되면서 점차 발전하고 있는 자연어 처리 방식을 1980년대로 거슬러 올라가 순서대로 한 꼬집씩 짚어보고, 비교적 최근 개발된 모델(알고리즘)인 트랜스포머, 어텐션 알고리즘, GPT와 ELMO, BERT 등에 대해서도 가볍게 한 번 알아보겠습니다.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 기초 - 파이썬으로 텍스트를 다루는 기본 문법"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "문장 = \"동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"하느님\"이 문장 변수 안에 있는지 확인 : True를 리턴\n",
    "\"하느님\" in 문장"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 내 \"백두산\"이 출현하는 인덱스 : 5\n",
    "문장.index(\"백두산\")  # 파이썬 인덱스는 0부터 올라감"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"우리나라\"는 문장 변수에서 몇 번째 단어인가? : 6번째(인덱스는 0부터)\n",
    "문장.split().index(\"우리나라\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "'마르고'"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 변수의 세 번째 단어(마르고)를 리턴하려면?\n",
    "문장.split()[2]  # 0:동해물과, 1:백두산이, 2:마르고"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "'세만 라나리우 사하우보 이님느하 록도닳 고르마 이산두백 과물해동'"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 변수의 글자 순서를 역순 정렬하여 리턴하려면?\n",
    "문장[::-1]  # [시작인덱스(생략함) : 끝인덱스(생략함) : 간격(뒤로1칸씩)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동해물과만세\n"
     ]
    }
   ],
   "source": [
    "# 문장 변수의 첫 번째 단어와 마지막 단어를 연결하려면?  # \"동해물과만세\"\n",
    "단어리스트 = 문장.split()\n",
    "첫번째단어 = 단어리스트[0]\n",
    "마지막단어 = 단어리스트[-1]\n",
    "시작과끝단어 = 첫번째단어 + 마지막단어\n",
    "\n",
    "print(시작과끝단어)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "['동해물과', '마르고', '하느님이', '우리나라']"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 짝수 인덱스(0, 2, 4, ..)의 단어만 출력하려면?  # 동해물과 마르고 하느님이 우리나라\n",
    "[단어리스트[i] for i in range(len(단어리스트)) if i % 2 == 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "'나라 만세'"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 변수의 마지막 다섯 글자만 출력하려면?  # \"나라 만세\"\n",
    "문장[-5:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "'과물해동 이산두백 고르마 록도닳 이님느하 사하우보 라나리우 세만'"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 순서는 유지하면서 글자 순서만 역순으로 출력하려면?\n",
    "\" \".join(단어[::-1] for 단어 in 단어리스트)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "'hello world!'"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대소문자를 전부 소문자로 바꾸려면?\n",
    "\"Hello World!\".lower()  # 대문자는 .upper()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 자연어 처리의 시작 : 토큰화\n",
    "\n",
    "위의 문법이면 웹에서 수집한 텍스트나 DB, 스토리지에서 가져온 텍스트자료를 가지고 기본적인 전처리를 수행하는 데 충분할 것입니다. 이제 \"토큰화\"부터 본격적인 NLP 단계의 전처리를 시작해봅시다.\n",
    "\n",
    "토큰화Tokenization는 문장을 구성 단어로 나누는 절차를 말합니다.\n",
    "\n",
    "### \"나는 책을 읽고 있다.\"\n",
    "\n",
    "위 문장에서 가장 먼저 처리할 작업은 이 문장의 단어(토큰)를 추출하는 것입니다. 가장 기본적인 방법은 한 단어씩 구분짓는 것입니다. 부호도 포함해서요.\n",
    "\n",
    "### [\"나는\", \"책을\", \"읽고\", \"있다\", \".\"]\n",
    "\n",
    "이렇게 한 번에 한 단어씩 토큰을 추출했습니다. 이런 경우를 유니그램Unigram이라고 부릅니다. (Uni는 1을 뜻함)\n",
    "\n",
    "경우에 따라 두 개나 세 개의 토큰을 추출할 수도 있습니다.\n",
    "\n",
    "### [\"나는 책을\", \"책을 읽고\", \"읽고 있다\", \"있다.\"]\n",
    "\n",
    "이렇게 두 개씩 묶어 만들면 바이그램Bi-Gram, 세 개씩 묶으면 트라이그램Tri-Gram이라고 부릅니다. 자주는 아니지만 경우에 따라 4개 이상의 단어로 토큰을 추출할 경우 n-그램이라고 부릅니다. (여기서 n은 자연수)\n",
    "\n",
    "지금까지 설명드린 것이 \"단어레벨(Word Level)\"의 엔그램이고, 필요에 따라 글자단위Character level) 엔그램으로 토큰을 생성하기도 합니다. 아래처럼요. (캐릭터레벨 토큰화는 대부분 스페이스를 한 개의 글자로 간주합니다.)\n",
    "\n",
    "### [\"나는 \", \"는 책\", \" 책을\", \"책을 \", \"을 읽\", \" 읽고\", \"읽고 \", \"고 있\", \" 있다\", \"있다.\"]\n",
    "\n",
    "## n-gram의 활용\n",
    "\n",
    "왜 엔그램을 알아야 할까요? 자연어처리에서 엔그램은 의외로 많은 곳에 사용됩니다. 자연어처리를 활용하는 몇 가지 애플리케이션이 있는데, 예를 들면 인풋박스에 뭔가 타이핑을 할 때 다음 단어가 무엇이 오는지 예측을 할 수 있겠죠? 오타 같은 것을 발견해서 다른 단어를 추천해줄 수도 있을 겁니다. (현재는 대부분 머신러닝 기반 추천 알고리즘을 사용하고 있습니다.)\n",
    "\n",
    "## n-gram의 장점\n",
    "\n",
    "엔그램과 대조되는 또 다른 토큰화 기법으로 Bag-of-Words가 있습니다. 말 그대로 \"단어가방\"인데요. 바로 다음 순서에 소개드리겠지만, BoW는 단어의 순서가 철저하게 무시됩니다. 엔그램을 쓰면 이 문제를 극복하고 어느 정도 문맥을 유지할 수 있거든요. 여기서 잠깐 BoW의 개념에 대해서도 한 번 짚고 돌아오겠습니다.\n",
    "\n",
    "## BoW - Bag of Words\n",
    "\n",
    "아래와 같은 문장이 있다고 생각해보겠습니다.\n",
    "\n",
    "### \"machine learning is fun and is not boring\"\n",
    "\n",
    "이걸 BoW로 만들면 아래처럼 바뀝니다.\n",
    "\n",
    "![](https://i.ibb.co/5hfBRxq/256.png)\n",
    "\n",
    "첫 번째 문제는 머신러닝이라는 문맥적인 것을 알고 싶은데 BoW는 머신이 한 개고 러닝이 한 개라고만 알려줍니다.\n",
    "\n",
    "두 번째 문제는 바로 not의 위치입니다. 주어진 문장은, \"머신러닝은 fun하고 boring하지 않다\"는 뜻인데, BoW로 넘어가면 is fun and is not boring이나, is not fun and is boring이나 동일한 BoW가 되어버립니다.\n",
    "\n",
    "이 문장을 단어레벨 바이그램으로 토큰화하면 어떻게 될까요?\n",
    "\n",
    "### [\"machine learning\", \"learning is\", \"is fun\", \"fun and\", \"and is\", \"is not\", \"not boring\"]\n",
    "\n",
    "차이가 보이시나요? 머신러닝이라는 단어가 한 개의 토큰이 되었고, not boring이 하나의 토큰이 되어서 not이 boring과 붙어있다는 걸 컴퓨터가 인식할 수 있겠죠? (어떻게 인식하는지는 조금 뒤에서 다루겠습니다.)\n",
    "\n",
    "이렇게 엔그램을 활용한 bag of bigram으로 토큰을 만들었을 때 인식률이나 퍼포먼스가 올라갈 것으로 예상할 수 있습니다. 문맥적인 부분을 숫자로 표현할 수 있게 되었으니까요.\n",
    "\n",
    "엔그램이 활용되는 또 다른 예제는 바로 Next word prediction(다음 단어 예측)입니다. 현재는 굉장히 발전된 단어예측 알고리즘들이 있지만, 예전에는 이런 방식으로도 다소나마 구현이 가능했습니다.\n",
    "\n",
    "how are you doing, how are you, how are they라는 데이터가 입력되어 있을 때, 트라이그램으로 토큰화를 했다면 대략\n",
    "\n",
    "### how are you\n",
    "### are you doing\n",
    "### how are you\n",
    "### how are they\n",
    "\n",
    "이런 네 개의 토큰이 만들어졌을 겁니다. 이를 기반으로 사용자가 검색창에 \"how are\"를 입력했다면? 이 알고리즘은 카운트 기반으로 \"you\"를 추천해줄 수 있습니다.\n",
    "\n",
    "![](https://i.ibb.co/93qpH2C/257.png)\n",
    "\n",
    "마지막으로 엔그램을 활용하는 또 다른 예로, 스펠체크를 할 수 있을 겁니다.\n",
    "\n",
    "### quality\n",
    "### quarter\n",
    "### quit\n",
    "\n",
    "이렇게 스펠체커의 knowledge base data에 세 개의 단어로 바이그램이 입력된 상태에서 \"qwal\"을 입력하면?\n",
    "\n",
    "![](https://i.ibb.co/4K44sQB/258.png)\n",
    "\n",
    "qual이라고 추천해줄 수 있겠죠?\n",
    "\n",
    "이제 토큰화를 파이썬 코드로 간단히 구현해보겠습니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\smj02\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\smj02\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "words = word_tokenize(\"We are studying NLP Fundamentals\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "['We', 'are', 'studying', 'NLP', 'Fundamentals']"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def generate_N_grams(text, ngram=1):\n",
    "    \"nltk의 불용어 사전 활용한 n그램 함수\"\n",
    "    words = [word for word in text.split(\" \") if word not in set(stopwords.words('english'))]\n",
    "    temp = zip(*[words[i:] for i in range(0, ngram)])\n",
    "    ans = [' '.join(ngram) for ngram in temp]\n",
    "    return ans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "['We', 'studying', 'NLP', 'Fundamentals']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram = generate_N_grams(\"We are studying NLP Fundamentals\")\n",
    "unigram"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "['We studying', 'studying NLP', 'NLP Fundamentals']"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = generate_N_grams(\"We are studying NLP Fundamentals\", 2)\n",
    "bigram"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TF-IDF\n",
    "\n",
    "엔그램이나 BoW를 이용한 NGD 알고리즘은 복잡한 자연어처리에 한계가 있었습니다. 품사를 직접 태깅해야 했고, 불용어를 제거해야 하며, 텍스트 정규화, 철자수정, 어간추출이나 단어의 중의성 문제 등.. 수많은 문제를 해결해야 했습니다. 특히 표제어를 추출하거나문서간 유사도를 측정하는 등의 간단한 연산도 \"단어가 몇 번 들어가는가?\" 정도의 숫자세기에서 그치게 되었습니다.\n",
    "\n",
    "이런 문제에 대한 진일보한 해결책들이 하나씩 개발되었는데, TF-IDF도 그 중 하나입니다. TF-IDF는 Term Frequency - Invese Document Frequency의 약자입니다. Term이란 문장이 주어졌을 때 단어를 뜻한다고 보시면 됩니다. 이걸 왜 사용하게 되었을까요? 문서, 즉 문장들은 단어로 구성되어 있는데, 이 단어들을 통해 문서의 연관성을 알고 싶을 때 TF-IDF 알고리즘을 사용합니다. 문장을 구성하는 단어별로 문서에 대한 \"정보\"를 얼마나 많이 가지고 있을까 하는 것을 \"숫자\"로 표현할 수 있는 알고리즘입니다.\n",
    "\n",
    "먼저 알아볼 것은 TF입니다. 문서가 주어졌을 때 단어가 몇 번씩 주어졌는지. 문서 안에 단어가 여러 번 출현했다면 연관성이 높을 것이라는 가정하에 빈도에 의한 점수를 매깁니다.\n",
    "\n",
    "![](https://i.ibb.co/pZNJkcK/259.png)\n",
    "\n",
    "car가 가장 빈도가 높고 가장 중요한 단어로 간주해도 될 것입니다. 그런데 TF스코어만 사용하면 치명적인 단점이 있습니다. 바로 \"흔한 단어\" 때문인데요.\n",
    "\n",
    "![](https://i.ibb.co/BTtQQjj/260.png)\n",
    "\n",
    "a와 friend가 공동1등입니다. 문서와 연관성은 깊지 않지만 관사나 대명사 외에도 여러 문서에 자주 출현하는 흔한 단어가 있을 것입니다. 이러한 단어들에 패널티를 주기 위해 IDF라는 개념을 사용하는데요. 공식은 간단합니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Log(Total # of Docs / # of Docs with the term in it)\n",
    "\n",
    " 로그 안에서 총 문장의 갯수를 단어가 출현한 문장의 갯수로 나눠준 값입니다. 수학적 오류를 피하기 위해 분모에 1을 더해주기도 합니다.\n",
    "\n",
    "![](https://i.ibb.co/g3RBcZ0/263.png)\n",
    "\n",
    "TF와 IDF를 곱하면 아래와 같은 결과가 나옵니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://i.ibb.co/7K2HBZb/263.png)\n",
    "\n",
    "문장A에서 TF-IDF값이 가장 높은 단어는 0.13의 car이고,\n",
    "문장B에서는 0.08로 friend라는 것을 볼 수 있습니다.\n",
    "\n",
    "문장B에서 가장 핵심이 되는 단어, 문장과 가장 연관성이 높은 단어가 각각 car와 friend라는 의미이기도 합니다.\n",
    "\n",
    "요약하면 문서, 문장이 주어졌을 때 TF-IDF는 각 단어별로 문장과의 연관성을 수치로 나타낸 값이라고 볼 수 있습니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# word2vec\n",
    "\n",
    "이제 본격적으로 단어를 벡터로 변환하는 알고리즘인 word2vec에 대해 알아보겠습니다.\n",
    "\n",
    "딥러닝 모델에 텍스트를 넣을 수 없죠. 숫자는 넣을 수 있습니다. 자연어처리의 대상은 텍스트인데, 이를 숫자로 바꾸는 것을 인코딩이라고 합니다.\n",
    "\n",
    "\"thank you\"와 \"I love you\"라는 문장이 주어졌을 때 가장 간단한 방법은 출현 순서대로 숫자를 매기는 방법일 것입니다.\n",
    "\n",
    " {thank : 0,\n",
    " you   : 1,\n",
    " I     : 2,\n",
    " love  : 3}\n",
    "\n",
    "이런 식으로 단순하게요.\n",
    "하지만 딥러닝에서 많이 쓰이는 방법은 원-핫 인코딩입니다. 독립적인 벡터를 만들어주는 방법이죠.\n",
    "\n",
    "{thank : [1, 0, 0, 0],\n",
    " you   : [0, 1, 0, 0],\n",
    " I     : [0, 0, 1, 0],\n",
    " love  : [0, 0, 0, 1]}\n",
    "\n",
    "그런데 이런 방식의 단점은 단어간의 유사도를 알 수 없다는 것입니다. \"고맙다\"와 \"사랑한다\"는 \"고맙다\"와 \"미워한다\"보다 좀 더 가까워야할텐데, 원핫인코딩으로는 그 정보를 표현할 수가 없습니다. 모든 단어 벡터간의 거리가 같아요. 유클리드거리도 전부 동일하고, 코사인유사도를 구하려고 해도 전부 직교하는 벡터니까요.\n",
    "\n",
    "이러한 문제 때문에 \"임베딩embedding\"이라는 개념이 도입되었습니다.\n",
    "\n",
    "인코딩 대신에 임베딩을 사용함으로써 단어벡터끼리의 유사도를 구할 수가 있게 됩니다. 임베딩은 원핫인코딩보다 오히려 차원도 적으면서 유사도를 갖게 됩니다. (학습방법은 아래에서 설명하겠습니다.)\n",
    "\n",
    "![](https://i.ibb.co/9szggXh/264.png)\n",
    "\n",
    "비슷한 단어는 서로 가까이 분포하는 것을 보실 수 있습니다.\n",
    "\n",
    "word2vec은 여러가지 임베딩 기법 중 하나이고요. 이 유사도 같은 경우에는 비슷한 위치에 있는 단어들을 통해 유사도 값을 얻게 됩니다. 참고로 비슷한 위치에 있는 단어들을 \"이웃\"이라고 합니다.\n",
    "\n",
    "word2vec 데이터를 생성하는 가장 단순한 방법은 바로 이웃 단어를 활용한 skipgram을 통해 학습하는 것입니다. skipgram을 간단히 설명드리겠습니다. 여기부터는 반갑게도 우리에게 익숙한 \"머신러닝\"과 \"학습\"개념이 나옵니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 스킵그램 : word2vec 데이터 생성\n",
    "\n",
    "스킵그램은 word2vec 데이터를 생성하는 알고리즘입니다. 몇 개의 이웃을 선택하느냐 하는 개념을 \"window size\"라고 부릅니다. 윈도우사이즈가 1이면 왼쪽과 오른쪽으로 하나씩의 이웃만 보겠다는 겁니다.\n",
    "\n",
    "예제를 통해 설명드리겠습니다.\n",
    "\n",
    "### \"king brave man\"\n",
    "\n",
    "### \"queen beautiful woman\"\n",
    "\n",
    "이 두 문장을 가지고 스킵그램을 작성해보겠습니다.\n",
    "\n",
    "![](https://i.ibb.co/mFGkYFC/266.png)\n",
    "\n",
    "king의 이웃은 brave,\n",
    "brave의 이웃은 king과 man이겠죠?\n",
    "이런 식으로 위의 표를 만듭니다.\n",
    "\n",
    "딥러닝 모델의 인풋이 word 열이고,\n",
    "타겟이 neighbor가 됩니다.\n",
    "\n",
    "경사하강법으로 컴퓨터가 직접 데이터를 만듭니다.\n",
    "\n",
    "윈도우사이즈가 2라면 어떻게 될까요?\n",
    "\n",
    "![](https://i.ibb.co/xDwvCXj/267.png)\n",
    "\n",
    "딥러닝 모델에 들어갈 데이터는 \"텍스트\"가 아니라 인코딩한 값인 \"벡터\"가 들어가게 됩니다. 아래처럼요.\n",
    "\n",
    "![](https://i.ibb.co/xH2g9hm/268.png)\n",
    "\n",
    "이렇게 인풋과 타겟을 주고 중간에 은닉층의 가중치 값을 얻게 되는 겁니다.\n",
    "\n",
    "딥러닝 모델은 대략 아래와 같이 생겼습니다. (예시임)\n",
    "\n",
    "<img src=\"https://i.ibb.co/gyP9R94/269.png\" width=\"1000\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "원핫인코딩한 벡터가 그대로 6개의 인풋레이어가 되고, 히든레이어의 두 개의 가중치는 \"2차원의 벡터\"를 만들겠다는 의미입니다.\n",
    "\n",
    "w1은 (스칼라값이 아니라) [w11, w12, w13, w14, w15, w16]로, 6차원 형태의 벡터이고,\n",
    "\n",
    "w2도 동일하게 [w21, w22, w23, w24, w25, w26] 입니다.\n",
    "\n",
    "king은 원핫인코딩 변환시 [1, 0, 0, 0, 0, 0] 이었습니다.\n",
    "\n",
    "초기화된 w1, w2를 지나서 출력레이어(소프트맥스를 적용한) 값이 [0.1, 0.9, 0, 0, 0, 0] 이 나왔는데\n",
    "\n",
    "그런데 타겟 값은 [0, 1, 0, 0, 0, 0] 으로 작은 오차가 발생했습니다.\n",
    "\n",
    "이 오차값을 가지고 크로스엔트로피 오차함수loss function를 돌려서 되돌아가 w1과 w2를 옵티마이징합니다.\n",
    "\n",
    "(지난 딥러닝 기초 시간에 이런 방식의 오차보정 과정을 \"역전파 알고리즘\"이라고 불렀습니다.)\n",
    "\n",
    "이를 반복해서 최적의 w1과 w2를 구합니다.\n",
    "\n",
    "### word2vec은 어디 있나요?\n",
    "\n",
    "다소 복잡한 과정을 통해서 가중치 w1과 w2가 최적화되었습니다. 그런데 말입니다. 모델학습은 완료되었는데, 애초에 우리가 구하고자 했던 건 바로 word2vec이었죠?\n",
    "\n",
    "이제 word2vec은 어떻게 구할까요?\n",
    "\n",
    "### 학습된 가중치가 바로 word2vec입니다.\n",
    "\n",
    "재미있게도 우리는 이미 word2vec을 얻었습니다.\n",
    "\n",
    "학습된 가중치 w1, w2가 바로 인풋벡터(단어)들의 word2vec, 즉 임베딩 값입니다.\n",
    "\n",
    "<img src=\"https://i.ibb.co/2tPyH3J/271.png\" width=\"1000\"/>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "단어 각각의 원핫인코딩 벡터와 은닉층의 가중치를 곱하면 w1, w2의 다른 가중치들은 모두 0이 되고 단어에 해당하는 2차원 벡터만 남게 됩니다.\n",
    "\n",
    "이렇게 히든 레이어 값들을 2차원 좌표에 표시해보면,\n",
    "\n",
    "<img src=\"https://i.ibb.co/XW6WjC7/272.png\" width=\"1000\"/>\n",
    "\n",
    "man과 king이 비슷한 위치에 있고, woman과 queen이 비슷한 위치에 있네요. 보시는 바와 같이 인코딩은 6차원 벡터였지만 임베딩은 2차원 벡터가 되었고, 유사도를 구현해낸 것을 보실 수가 있습니다.\n",
    "\n",
    "pip로 word2vec 모듈을 설치하실 수도 있지만, 여러분의 PC에, 혹은 구글 콜랩에서 텐서플로를 통해서도 word2vec을 구현해보실 수 있습니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# word2vec 실습(tensorflow)\n",
    "\n",
    "아래 예제코드는 \"나의 첫 머신러닝/딥러닝\"의 저자이자,\n",
    "딥러닝 분야 전문(?) 유튜버이신 허민석 님의 깃헙 튜토리얼을 참고했습니다.\n",
    "위 책도 유명하지만, 이 분의 유튜브 채널은 정말 '무료로 이렇게까지 알려주나?' 싶을 만큼\n",
    "쉽게 설명을 잘 해주시는 걸로 정평이 나 있습니다. 꼭 한 번 들어가보시기를 추천드립니다.\n",
    "\n",
    "<a href=\"https://www.youtube.com/user/TheEasyoung\">허민석 님의 유튜브 채널</a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# 10개 예시문장 입력\n",
    "\n",
    "corpus = ['king is a strong man',\n",
    "          'queen is a wise woman',\n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong',\n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "['king strong man',\n 'queen wise woman',\n 'boy young man',\n 'girl young woman',\n 'prince young king',\n 'princess young queen',\n 'man strong',\n 'woman pretty',\n 'prince boy king',\n 'princess girl queen']"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불용어\n",
    "stop_words = ['is', 'a', 'will', 'be']\n",
    "\n",
    "\n",
    "# 불용어 제거함수 정의\n",
    "def remove_stop_words(corpus, stop_words):\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# 불용어 배제\n",
    "corpus = remove_stop_words(corpus, stop_words)\n",
    "corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "{'boy',\n 'girl',\n 'king',\n 'man',\n 'pretty',\n 'prince',\n 'princess',\n 'queen',\n 'strong',\n 'wise',\n 'woman',\n 'young'}"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corpus에서 단어 추출\n",
    "\n",
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words)  # set 자료형은 \"집합\"개념과 유사하며, 중복값이 제거되지만, 순서가 섞임\n",
    "\n",
    "words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "{'boy': 0,\n 'man': 1,\n 'prince': 2,\n 'strong': 3,\n 'young': 4,\n 'girl': 5,\n 'wise': 6,\n 'princess': 7,\n 'pretty': 8,\n 'queen': 9,\n 'woman': 10,\n 'king': 11}"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int = {}  # 사전 자료형 - {키:값..} 형태\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    word2int[word] = i  # 단어를 키로, 인덱스를 값으로\n",
    "\n",
    "word2int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "[['king', 'strong', 'man'],\n ['queen', 'wise', 'woman'],\n ['boy', 'young', 'man'],\n ['girl', 'young', 'woman'],\n ['prince', 'young', 'king'],\n ['princess', 'young', 'queen'],\n ['man', 'strong'],\n ['woman', 'pretty'],\n ['prince', 'boy', 'king'],\n ['princess', 'girl', 'queen']]"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "for sentence in corpus:  # 각 문장을 단어별로 자르기\n",
    "    sentences.append(sentence.split())\n",
    "\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "[['king', 'strong'],\n ['king', 'man'],\n ['strong', 'king'],\n ['strong', 'man'],\n ['man', 'king'],\n ['man', 'strong'],\n ['queen', 'wise'],\n ['queen', 'woman'],\n ['wise', 'queen'],\n ['wise', 'woman'],\n ['woman', 'queen'],\n ['woman', 'wise'],\n ['boy', 'young'],\n ['boy', 'man'],\n ['young', 'boy'],\n ['young', 'man'],\n ['man', 'boy'],\n ['man', 'young'],\n ['girl', 'young'],\n ['girl', 'woman'],\n ['young', 'girl'],\n ['young', 'woman'],\n ['woman', 'girl'],\n ['woman', 'young'],\n ['prince', 'young'],\n ['prince', 'king'],\n ['young', 'prince'],\n ['young', 'king'],\n ['king', 'prince'],\n ['king', 'young'],\n ['princess', 'young'],\n ['princess', 'queen'],\n ['young', 'princess'],\n ['young', 'queen'],\n ['queen', 'princess'],\n ['queen', 'young'],\n ['man', 'strong'],\n ['strong', 'man'],\n ['woman', 'pretty'],\n ['pretty', 'woman'],\n ['prince', 'boy'],\n ['prince', 'king'],\n ['boy', 'prince'],\n ['boy', 'king'],\n ['king', 'prince'],\n ['king', 'boy'],\n ['princess', 'girl'],\n ['princess', 'queen'],\n ['girl', 'princess'],\n ['girl', 'queen'],\n ['queen', 'princess'],\n ['queen', 'girl']]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOW_SIZE = 2  # 스킵그램 윈도우사이즈 지정\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0): min(idx + WINDOW_SIZE, len(sentence)) + 1]:\n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])\n",
    "\n",
    "data  # 윈도우사이즈 2의 스킵그램 데이터 생성"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "    input   label\n0    king  strong\n1    king     man\n2  strong    king\n3  strong     man\n4     man    king\n5     man  strong\n6   queen    wise\n7   queen   woman\n8    wise   queen\n9    wise   woman",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>king</td>\n      <td>strong</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>king</td>\n      <td>man</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>king</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>strong</td>\n      <td>man</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>man</td>\n      <td>king</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>man</td>\n      <td>strong</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>queen</td>\n      <td>wise</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>queen</td>\n      <td>woman</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>wise</td>\n      <td>queen</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>wise</td>\n      <td>woman</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns=['input', 'label'])\n",
    "\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "(52, 2)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf  # 텐서플로 v1의 코드를 2.0 이상에서 실행해주는 모듈\n",
    "import numpy as np\n",
    "\n",
    "tf.disable_v2_behavior()  # 텐서플로 v2 기능 비활성화\n",
    "\n",
    "ONE_HOT_DIM = len(words)  # 원핫인코딩 벡터의 길이(차원 수) 결정(12개 단어이므로 12차원)\n",
    "\n",
    "\n",
    "# 원핫인코딩벡터 생성함수 정의\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)  # 전부 0으로 채워놓고\n",
    "    one_hot_encoding[data_point_index] = 1  # 해당하는 인덱스에만 1 입력\n",
    "    return one_hot_encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])]"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []  # 입력단어 리스트\n",
    "Y = []  # 타겟단어 리스트\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[x]))\n",
    "    Y.append(to_one_hot_encoding(word2int[y]))\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# making placeholders for X_train and Y_train  # tf.v1 전용 메서드로 v2에서 제거됨ㅜ\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "# 워드임베딩은 2차원 적용(시각화를 위해)\n",
    "EMBEDDING_DIM = 2\n",
    "\n",
    "# 은닉층 가중치와 편향 정의(가중치는 최종적으로 워드벡터가 될 예정)\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))  # 12, 2\n",
    "b1 = tf.Variable(tf.random_normal([1]))\n",
    "hidden_layer = tf.add(tf.matmul(x, W1), b1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# 출력층 정의\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))  # 2, 12\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add(tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "# loss function: cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# 훈련 정의(학습률learning rate = 0.05)\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 loss is : 4.4689507484436035\n",
      "iteration 3000 loss is : 1.7747855186462402\n",
      "iteration 6000 loss is : 1.7185957431793213\n",
      "iteration 9000 loss is : 1.693145990371704\n",
      "iteration 12000 loss is : 1.6801139116287231\n",
      "iteration 15000 loss is : 1.6716334819793701\n",
      "iteration 18000 loss is : 1.6654167175292969\n"
     ]
    }
   ],
   "source": [
    "# 세션 정의 및 학습 시작\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "iteration = 20000\n",
    "for i in range(iteration):\n",
    "    # 입력값인 X_train은 현재 원핫인코딩된 각각의 단어 벡터\n",
    "    # 레이블(타겟값)은 원핫인코딩된 이웃단어 벡터\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 3000 == 0:  # 매 3,000회마다 오차 모니터링\n",
    "        print(f'iteration {str(i)} loss is : {sess.run(loss, feed_dict={x: X_train, y_label: Y_train})}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.94628704  0.6693933 ]\n",
      " [-3.3740416   3.5456753 ]\n",
      " [-4.2270617   4.0713596 ]\n",
      " [-2.749609   -1.3697888 ]\n",
      " [-0.03993738 -0.29263544]\n",
      " [ 1.7901714   0.9794548 ]\n",
      " [ 5.314395    2.7705908 ]\n",
      " [ 4.0996294   3.22924   ]\n",
      " [ 3.6869469  -0.516242  ]\n",
      " [ 0.7564027   0.3388496 ]\n",
      " [ 0.8927691   0.9816378 ]\n",
      " [-0.8855157   0.8122522 ]]\n"
     ]
    }
   ],
   "source": [
    "# 은닉층의 가중치 W1에 요소별로 편향값을 더한 값이 최종 워드임베딩 벡터값임\n",
    "vectors = sess.run(W1 + b1)\n",
    "print(vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.9025042 , -0.2868239 ],\n       [-4.330259  ,  2.589458  ],\n       [-5.183279  ,  3.1151426 ],\n       [-3.7058263 , -2.326006  ],\n       [-0.99615455, -1.2488526 ],\n       [ 0.8339543 ,  0.02323763],\n       [ 4.3581777 ,  1.8143736 ],\n       [ 3.143412  ,  2.273023  ],\n       [ 2.7307296 , -1.4724592 ],\n       [-0.19981448, -0.61736757],\n       [-0.06344809,  0.02542062],\n       [-1.8417329 , -0.14396495]], dtype=float32)"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 참고\n",
    "\n",
    "W1 = sess.run(W1)\n",
    "W1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.95621717], dtype=float32)"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 참고\n",
    "\n",
    "b1 = sess.run(b1)\n",
    "b1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.94628704,  0.6693933 ],\n       [-3.3740416 ,  3.5456753 ],\n       [-4.2270617 ,  4.0713596 ],\n       [-2.749609  , -1.3697888 ],\n       [-0.03993738, -0.29263544],\n       [ 1.7901714 ,  0.9794548 ],\n       [ 5.314395  ,  2.7705908 ],\n       [ 4.0996294 ,  3.22924   ],\n       [ 3.6869469 , -0.516242  ],\n       [ 0.7564027 ,  0.3388496 ],\n       [ 0.8927691 ,  0.9816378 ],\n       [-0.8855157 ,  0.8122522 ]], dtype=float32)"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 참고\n",
    "\n",
    "W1 + b1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "          x1        x2      word\n0  -0.946287  0.669393       boy\n1  -3.374042  3.545675       man\n2  -4.227062  4.071360    prince\n3  -2.749609 -1.369789    strong\n4  -0.039937 -0.292635     young\n5   1.790171  0.979455      girl\n6   5.314395  2.770591      wise\n7   4.099629  3.229240  princess\n8   3.686947 -0.516242    pretty\n9   0.756403  0.338850     queen\n10  0.892769  0.981638     woman\n11 -0.885516  0.812252      king",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.946287</td>\n      <td>0.669393</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-3.374042</td>\n      <td>3.545675</td>\n      <td>man</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-4.227062</td>\n      <td>4.071360</td>\n      <td>prince</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-2.749609</td>\n      <td>-1.369789</td>\n      <td>strong</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.039937</td>\n      <td>-0.292635</td>\n      <td>young</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.790171</td>\n      <td>0.979455</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5.314395</td>\n      <td>2.770591</td>\n      <td>wise</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4.099629</td>\n      <td>3.229240</td>\n      <td>princess</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.686947</td>\n      <td>-0.516242</td>\n      <td>pretty</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.756403</td>\n      <td>0.338850</td>\n      <td>queen</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.892769</td>\n      <td>0.981638</td>\n      <td>woman</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>-0.885516</td>\n      <td>0.812252</td>\n      <td>king</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df로 변환\n",
    "\n",
    "w2v_df = pd.DataFrame(vectors, columns=['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "        word        x1        x2\n0        boy -0.946287  0.669393\n1        man -3.374042  3.545675\n2     prince -4.227062  4.071360\n3     strong -2.749609 -1.369789\n4      young -0.039937 -0.292635\n5       girl  1.790171  0.979455\n6       wise  5.314395  2.770591\n7   princess  4.099629  3.229240\n8     pretty  3.686947 -0.516242\n9      queen  0.756403  0.338850\n10     woman  0.892769  0.981638\n11      king -0.885516  0.812252",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>x1</th>\n      <th>x2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>boy</td>\n      <td>-0.946287</td>\n      <td>0.669393</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>man</td>\n      <td>-3.374042</td>\n      <td>3.545675</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>prince</td>\n      <td>-4.227062</td>\n      <td>4.071360</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>strong</td>\n      <td>-2.749609</td>\n      <td>-1.369789</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>young</td>\n      <td>-0.039937</td>\n      <td>-0.292635</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>girl</td>\n      <td>1.790171</td>\n      <td>0.979455</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>wise</td>\n      <td>5.314395</td>\n      <td>2.770591</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>princess</td>\n      <td>4.099629</td>\n      <td>3.229240</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>pretty</td>\n      <td>3.686947</td>\n      <td>-0.516242</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>queen</td>\n      <td>0.756403</td>\n      <td>0.338850</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>woman</td>\n      <td>0.892769</td>\n      <td>0.981638</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>king</td>\n      <td>-0.885516</td>\n      <td>0.812252</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 칼럼순서 정렬\n",
    "\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 2880x1440 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2차원 평면에 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(word, (x1, x2))\n",
    "\n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    "\n",
    "plt.xlim(x_axis_min, x_axis_max)\n",
    "plt.ylim(y_axis_min, y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (40, 20)\n",
    "plt.rcParams[\"font.size\"] = 30\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "이것으로 word2vec의 실습을 마칩니다.\n",
    "\n",
    "간단한 설명과 실습을 통해 단어가 어떤 과정을 통해 숫자로 바뀌는지 알아보았습니다.\n",
    "컴퓨터가 어떤 방식으로 주어진 단어의 의미를 이해할 수 있는지를 막연하게나마 아시겠죠?\n",
    "\n",
    "아래에 설명드릴 (비교적) 최신 언어모델인 GPT도 이와 유사한 방식으로 대량의 텍스트데이터를 통해 비지도 선행학습을 거친 후에\n",
    "원하는 실행형태에 따라 파인튜닝을 적용하고 최종 레이어를 추가하는 단계를 거치게 됩니다.\n",
    "(GPT는 이후에 보다 자세히 설명드리겠습니다.)\n",
    "\n",
    "이제 본격적인 순차적데이터 처리모델인 RNN으로 넘어가봅시다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN 기초\n",
    "\n",
    "RNN은 순차적인 데이터를 입력받아 결괏값을 도출하는 데 사용하는 딥러닝 모델입니다. 대표적으로 자연어 처리에 많이 사용됩니다.\n",
    "\n",
    "아래는 RNN의 필요성을 강조하는 유명한 예제입니다.\n",
    "\n",
    "###  I work at Google\n",
    "\n",
    "### I google at work\n",
    "\n",
    "두 문장의 품사를 보면 각각\n",
    "I(대명사) work(동사) at(전치사) Google(명사)\n",
    "\n",
    "두 번째 문장의 구성은\n",
    "I(대명사) google(동사) at(전치사) work(명사)\n",
    "\n",
    "입니다.\n",
    "\n",
    "같은 입력값(단어)임에도 다른 출력값(품사)이 나온 이유는 바로\n",
    "이전의 입력값들이 현재 입력값(단어)의 출력값(품사)에 영향을 주기 때문입니다.\n",
    "\n",
    "순차적인 구성을 고려하지 않는다면 이런 정보들이 모두 소실되어버릴 것입니다.\n",
    "그러면 RNN의 구조는 어떤 방식으로 이전 입력값들을 고려하고,\n",
    "결과적으로 출력값을 보완하게 될까요?\n",
    "\n",
    "바로 가중치(w, b) 외에 상태값(state)을 통해서 이전 셀(뉴런)의 정보를 제공받게 됩니다.\n",
    "상태값은 대략 tanh(입력값*wx + 이전셀상태값*wh + 편향) 함수로 결정됩니다.\n",
    "(tanh는 탄젠트하이퍼볼릭 함수로, 시그모이드와 유사하게 -1에서 1까지의 값을 갖습니다.)\n",
    "\n",
    "일반적인 딥러닝 모델과 마찬가지로 w와 b는 최초 무작위로 부여하고, 학습을 통해 업데이트됩니다.\n",
    "\n",
    "간단한 RNN 실습예제인 품사구분 예제를 통해 RNN의 원리를 알아봅시다.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN 실습 : 텐서플로를 이용한 단어 품사 구분(간소화)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, SimpleRNN\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# 항상 같은 결과를 갖기 위해 랜덤 시드 설정\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "# I      [1,0,0,0]\n",
    "# work   [0,1,0,0]\n",
    "# at     [0,0,1,0]\n",
    "# google [0,0,0,1]\n",
    "#\n",
    "# I work at google =  [ [1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1] ]\n",
    "# I google at work =  [ [1,0,0,0], [0,0,0,1], [0,0,1,0], [0,1,0,0] ]\n",
    "\n",
    "data = np.array([\n",
    "    [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]],\n",
    "    [[1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0]]\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 4, 4)]            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_9 (SimpleRNN)     [(None, 4, 3), (None, 3)] 24        \n",
      "=================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 입력값의 형태를 지정합니다.\n",
    "inputs = Input(shape=(4, 4))\n",
    "\"\"\"\n",
    "RNN 셀의 속성을 지정합니다.\n",
    "3: 3차원 벡터의 출력값 지정합니다.\n",
    "return_state=True: RNN 셀의 상태값(state)를 출력하도록 지정합니다.\n",
    "\"\"\"\n",
    "output, state = SimpleRNN(units=3, return_state=True, return_sequences=True)(inputs)\n",
    "model = Model(inputs=inputs, outputs=[output, state])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I work at google: \n",
      "[[-0.40221617  0.26811057  0.33349672]\n",
      " [-0.0293914   0.723282    0.50560576]\n",
      " [-0.2949671   0.91913986 -0.1186246 ]\n",
      " [ 0.55602175  0.1753935   0.705892  ]]\n",
      "I google at work: \n",
      "[[-0.40221617  0.26811057  0.33349672]\n",
      " [ 0.79245585 -0.39077425  0.52387464]\n",
      " [-0.58219475  0.62426084 -0.8174929 ]\n",
      " [-0.74801064  0.7835408   0.8668151 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python368\\lib\\site-packages\\keras\\engine\\training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "# 출력값, 상태값 프린트\n",
    "output, state = model.predict(data)\n",
    "\n",
    "print(\"I work at google: \")\n",
    "print(output[0])\n",
    "print(\"I google at work: \")\n",
    "print(output[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "두 문장의 첫단어 출력값이 동일합니다. 이는 첫단어에는 이전 상태값이 존재하지 않기 때문입니다.\n",
    "두번째 단어부터의 출력값은 두 문장이 다르게 나타납니다. 이는 이전 상태값이 현재 출력값에 영향을 주기 때문입니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I work at google: state:  [ 0.8013904  -0.15234374 -0.94260365]\n",
      "I google at work: state:  [ 0.41476357 -0.47476506 -0.8735651 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"I work at google: state: \", state[0])\n",
    "print(\"I google at work: state: \", state[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.8013904 , -0.15234374, -0.94260365],\n       [ 0.41476357, -0.47476506, -0.8735651 ]], dtype=float32)"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state  # (최종 상태값)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 본 예제는 제한적으로\n",
    "\n",
    "\"이전상태값의 영향으로 입력값이 같아도 출력값이 달라진다\"는 개념만 보여드렸습니다.\n",
    "타겟값으로 품사(대명사, 동사, 전치사, 명사)를 원핫인코딩해서 지정해주면(본 예제에서는 생략)\n",
    "RNN모델이 반복학습을 통해 적절한 아웃풋을 갖게 되고, 최종적으로 소프트맥스 함수를 통해\n",
    "각 품사에 해당할 확률(합은 1)을 출력하게 됩니다. 아래 그림을 참고해 주시기 바랍니다.\n",
    "\n",
    "![](https://i.ibb.co/XbL6DcW/273.png)\n",
    "\n",
    "![](https://i.ibb.co/D92d784/274.png)\n",
    "\n",
    "오차를 줄여나가는 과정을 통해서 Wxh(입력값에 대한 가중치)와 b(편향), Whh(이전상태값에 대한 가중치)를 최적화시켜갑니다. 어떻게 최적화하나요?\n",
    "경사하강법을 통해서 학습하게 됩니다.\n",
    "\n",
    "특이한 점은 Wxh와 Whh, b 등이 동일한 변수입니다. 하나의 변수가 바뀌는 것이기 때문에 back-propagation이라고 부르지 않고, back-propagation-through-time이라고 부릅니다. 줄여서 BPTT라고도 부릅니다.\n",
    "\n",
    "실제 품사태깅을 하는 모델은 토큰화와 품사레이블링이 완료된 대량의 학습데이터가 필요합니다.\n",
    "LSTM에 대한 설명까지 간단히 마친 후에 LSTM 모델로 nltk의 영어코퍼스를 통해 품사태깅 실습을 해보겠습니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM 기초\n",
    "\n",
    "왜 순차적 데이터를 처리하는 RNN이 개발되었는데, LSTM이라는 복잡한 모델이 필요했을까요? 아래 예제를 한 번 보겠습니다.\n",
    "\n",
    "![](https://i.ibb.co/BVRC1V2/275.png)\n",
    "\n",
    "우리는 수십 문장 뒤에 \"He\"라는 단어가 가려져 있더라도 예측을 할 수 있습니다. RNN도 기본적으로는 예측을 할 수 있을 것이라고 기대했는데, 실제로는 아주 긴 시퀀스 뒤의 단어를 예측할 때 문제가 발생했습니다. 짧은 시퀀스에는 잘 작동하던 RNN이, 문장이 길어질수록 예측성능이 현저히 떨어지는 것이었습니다.\n",
    "\n",
    "문장에 100개 이상의 단어가 있을 때 최종 상태값을 구할 때, 내부적으로는 100번 정도 각 셀의 미분값을 곱하게(체인룰) 됩니다. 모든 미분값이 1보다 작다면? 미분값들을 곱한 값은 0에 가까운 값이 되겠죠? (반대의 경우는 아주 큰 값이 되어 발산하게 될 거고요.) 그러면 학습을 아무리 길게 한다고 해도 가중치의 값이 거의 변하지 않아요. 굉장히 학습이 길어지면서 수렴이 어렵게 됩니다. (지난 시간에 그래디언트 소실에 대해 간단히 설명드린 적 있었죠?)\n",
    "\n",
    "그래서 엔지니어들이 고민 끝에 셀 내부에 \"메모리 셀\"을 추가하게 되었습니다. 메모리셀의 핵심은 \"필요에 따라 기억하고 잊어버리는 정보\"를 지닌 변수입니다. 내부적으로 세 개의 시그모이드 함수와 두 개의 탄젠트하이퍼볼릭 함수가 포함된 다소 복잡한 셀이 되었습니다.\n",
    "\n",
    "이제 LSTM은 John이라는 정보를 지니고 있을 때 \"He\"라는 출력값을 쉽게 예측할 수 있게 되고, 문서 중간쯤에 Jane이라는 새로운 정보가 입력되었을 때 John에 대한 상태값과 기억이 줄어들고, Jane이라는 정보에 의해 \"She\"라는 출력값을 예측할 수 있게 됩니다.\n",
    "\n",
    "보다 자세한 설명은 아래 포스팅과 동영상을 참고해 주시기 바랍니다.\n",
    "\n",
    "<a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Christopher Olah의 포스팅(유명함)</a>\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=bX6GLbpw-A4\">허민석 님의 유튜브 영상</a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM 실습 : 본격적인 품사 분류기\n",
    "\n",
    "언어모델 엔지니어들은 RNN이나 LSTM의 성능을 끌어올리기 위해 여러 가지 응용을 시도했습니다. 단어 임베딩이 아닌 캐릭터임베딩을 시도한다든지, 학습방향을 역순으로 진행해본다든지, 양방향으로 진행한다든지.. 이들의 느린 학습속도와 성능 개선을 위해 내부구조를 간소화해본다든지(Gated Recurrent Unit, GRU) 등등 말이죠.\n",
    "\n",
    "이번에는 양방향 LSTM인 BiLSTM을 통한 영어 품사분류기를 만들어보겠습니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "시간관계상 실습은 생략하되, 유익한 포스팅을 하나 남겨둡니다. 참고하시기 바랍니다.\n",
    "\n",
    "<a href=\"https://wikidocs.net/33532\">양방향 LSTM를 이용한 품사 태깅(Part-of-speech Tagging using Bi-LSTM) by 유원준</a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# seq2seq와 어텐션 모델\n",
    "\n",
    "### 가장 기초적인 기계번역 메커니즘, 단어별로 직역하기\n",
    "\n",
    "sequence to sequence 메커니즘과 어텐션 모델을 설명드리기 전에, 한 가지 예를 들어 보겠습니다.\n",
    "\n",
    "I love you를 한글로 번역하고 싶은데, 컴퓨터가어떤 방법을 사용하게 하면 좋을까요?\n",
    "\n",
    "가장 기초적인 방법은 단어 하나하나를 직역하는 것입니다.\n",
    "\n",
    "I 는 \"나는\"으로,\n",
    "\n",
    "love 는 \"사랑해\"로,\n",
    "\n",
    "you 는 \"널\"로 번역한 후 한 문장을 만들면?\n",
    "\n",
    "\"난 사랑해 널\" 이라고 (그다지 매끄럽지는 않지만) 번역이 완료되었습니다.\n",
    "\n",
    "하지만 이 예시에서 알 수 있듯이 한 가지 문제가 발생했습니다.\n",
    "\n",
    "그것은 영어와 한글의 문법, 특히 어순이 다르다는 점 때문에 발생한 오류입니다.\n",
    "\n",
    "(영어는 대표적인 주어-동사-목적어 순의 언어이고, 한글은 주어-목적어-동사 순입니다. 전치사 위치, 의문문 순서 등도 다르죠.)\n",
    "\n",
    "또 다른 문제도 발생할 수 있습니다. 예를 들면,\n",
    "\n",
    "\"How are you?\" 를 번역하고 싶은데, 아시다시피 실제 의미는 \"잘 지내?\" 입니다.\n",
    "\n",
    "생각해 보면 몇 가지 문제가 더 있을 것 같기도 하네요.\n",
    "\n",
    "예를 들면 문맥에 따른 중의어(간단한 예시로 present를 현재로 번역할지, 선물로 번역할지?)의 번역이나,\n",
    "\n",
    "\"Who are you with?\" 같은, 전치사를 고려해야 하는 문장 등등요.\n",
    "\n",
    "단어 직역 및 이어붙이기로는 제 아무리 옳은 단어를 찾아내도\n",
    "\n",
    "\"어떻게 이다 너는?\" 이라고 번역하게 될 것입니다.\n",
    "\n",
    "(십여 년 전까지의 영한 번역프로그램 수준이 이 정도에서 크게 벗어나지 않았던 것 같습니다.)\n",
    "\n",
    "\"How are you?\" 는 세 어절이고, \"잘 지내?\"는 두 어절인데\n",
    "\n",
    "굳이 긴 문장을 입력해보지 않더라도, 같은 단어 수로 번역하는 것이 얼마나 어색한 결과를 나타내는지 짐작하실 것입니다.\n",
    "\n",
    "하여튼 좋은 방법은 아니군요.\n",
    "\n",
    "## 시퀀스-투-시퀀스는 이 문제를 어떻게 해결했을까?\n",
    "\n",
    "이런 방식을 개선하기 위해 엔지니어들이 시도한 방식이 바로 \"인코더 - 디코더\" 모델입니다.\n",
    "\n",
    "이를 다른 용어로, \"시퀀스 투 시퀀스\"라고도 부릅니다. 이하 s2s라고 적겠습니다.\n",
    "\n",
    "s2s의 번역 과정을 간략히 알아보겠습니다.\n",
    "\n",
    "![](https://i.ibb.co/LzdYYkv/277.png)\n",
    "\n",
    "위에서 언급한 RNN을 사용해서 I부터 순차적으로 인코딩을 시작합니다.\n",
    "\n",
    "RNN 셀에 차례대로 I가 들어가고 love가 들어가고 you가 들어갑니다.\n",
    "\n",
    "최종적으로 세 개의 단어의 정보를 담은 상태값이 만들어졌습니다.\n",
    "\n",
    "이 상태값은 벡터 형식이며, \"I love you\"라는 문장의 함축적인(?) 의미를 담고 있습니다.\n",
    "\n",
    "이 최종 상태값을 context vector라고 부릅니다.\n",
    "\n",
    "이제 이 문장을 한글로 번역해보겠습니다.\n",
    "\n",
    "번역 과정은 아래 그림의 오른쪽 부분입니다.\n",
    "\n",
    "![](https://i.ibb.co/3cPPdKK/278.png)\n",
    "\n",
    "END 시그널이 리턴되면 번역이 종료됩니다.\n",
    "\n",
    "세 개의 단어가 입력되더라도 갯수에 상관없이 컨텍스트 벡터를 통해 두 개의 단어만 출력하고 번역이 끝날 수도 있고,\n",
    "\n",
    "입력한 단어의 순서에 구애받지 않고 컨텍스트 벡터의 정보를 통해 적절한 순서의 번역문장을 출력해낼 수 있게 되었습니다.\n",
    "\n",
    "그리고 이 아키텍처는 제법 성공적이었습니다.\n",
    "\n",
    "적절한 학습을 통해 단어 수에 구애받지 않으면서, 문장순서도 올바르게 출력해주는 번역모델이 만들어진 것입니다.\n",
    "\n",
    "그런데 역시나, 또다른 문제가 발생했습니다.\n",
    "\n",
    "RNN 셀을 통해 컨텍스트벡터를 생성함에 있어, 단어가 많아질수록 번역성능이 현저하게 떨어지는 치명적인 단점이 있었던 것입니다.\n",
    "\n",
    "고정된 사이즈의 컨텍스트 벡터에 긴 문장(여러 개의 단어)을 입력할 때\n",
    "\n",
    "컨텍스트벡터의 사이즈 안에 모든 정보를 함축하기에는 무리가 있었던 것입니다.\n",
    "\n",
    "![](https://i.ibb.co/qCkt7PY/279.png)\n",
    "\n",
    "무작정 컨텍스트벡터 사이즈를 늘리는 것으로는 긴 문장의 번역성능 문제가 해결되지 않았습니다.\n",
    "\n",
    "엔지니어들은 이 문제를 또 어떻게 해결했을까요?\n",
    "\n",
    "여기서 또 국뽕이 차오르는 시점이 다가옵니다.\n",
    "\n",
    "바로 뉴욕대 컴퓨터공학과 종신교수인 조경현님이\n",
    "\n",
    "AI 4대천황 중 하나이자 GAN의 창시자, 이언굿펠로의 스승인 요슈아 벤지오 교수와 함께 연구해서\n",
    "\n",
    "위의 인코더-디코더 아키텍쳐에서 인코더에 해당하는 RNN 셀과 컨텍스트벡터의 사용방법을 획기적으로 바꾸어버립니다.\n",
    "\n",
    "<a href=\"https://www.chosun.com/national/weekend/2021/07/03/42RF6ZBIURCBHGPGTDYKIH34CM/\">관련 기사</a>\n",
    "\n",
    "> 세계적 AI 석학으로 꼽히는 조경현(36) 뉴욕대 컴퓨터과학과 교수. ‘인공 지능 번역’의 역사를 새로 썼다고 평가받는 인물이다. 그가 스물아홉 살이던 2014년, 요슈아 벤지오 몬트리올대 교수와 함께 발표한 ‘신경망 기계 번역’ 개념은 기존 기계 번역의 패러다임을 뒤집어 버렸다. 구글 번역기 등 대부분 번역기가 이 개념을 활용한 것이다.\n",
    ">\n",
    "> 이 천재 공학자에게 쏠린 관심은 뜨겁다. 2015년 뉴욕대 교수로 임용된 지 4년 만에 종신 교수가 됐고, 작년까지 페이스북에서 연구 과학자로도 일했다. 구글, 아마존 등 굴지의 글로벌 IT 기업이 그의 연구를 후원했다. 네이버, 삼성전자, 현대자동차 등 국내 주요 기업의 자문도 맡고 있다. 얼마 전엔 국내 최고 권위 학술상인 ‘삼성호암상’ 공학 부문 수상자로 선정됐다.\n",
    ">\n",
    "> 상금은 타는 족족 기부하고, 남성 공학자이지만 여성 공학자 육성을 누구보다 강조한다. 최첨단 AI 전문가인데 정작 정부 지원이 필요한 분야는 인문학이라고 역설한다. (후략)\n",
    "\n",
    "관련논문 : https://arxiv.org/pdf/1409.0473.pdf\n",
    "\n",
    "중요한 점은 RNN, 즉 인코더의 역할을 무엇이 대체했느냐 하는 것입니다.\n",
    "\n",
    "여기서 바로 그 유명한 \"어텐션\"의 개념이 발생하게 됩니다.\n",
    "\n",
    "조경현 교수님의 인터뷰를 조금 가져와보았습니다.\n",
    "\n",
    "> –교수님이 고안한 ‘신경망 기계 번역’은 어떤 개념인지요.\n",
    ">\n",
    "> “기존 기계 번역은 원문과 번역본 사이에서 ‘단어’가 어떻게 번역됐는지 보고, 이 데이터를 기반으로 번역하는 시스템이었어요. 단어와 어순이 비슷한 언어끼리는 번역이 잘되는데, 한국어·영어처럼 완전히 다른 언어끼리는 엉터리 번역이 많았죠. ‘신경망 기계 번역’은 딥 러닝을 적용해 문장의 ‘맥락’을 파악해 번역하는 방식입니다.” 예컨대 과거엔 ‘나 말리지 마’란 문장을 번역기에 돌리면 ‘Don’t dry me’가 나왔지만, 요즘은 ‘Don’t stop me’가 나온다. AI가 접목된 결과인데, 그 핵심 기술이 조 교수가 고안한 개념에서 나왔다.\n",
    "\n",
    "이제 위 작동방식의 원리를 간단히 알아보겠습니다.\n",
    "\n",
    "### 어텐션의 원리\n",
    "\n",
    "입력값을 모두 주고 나서 리턴된 컨텍스트벡터 하나를 사용하는 방식에 비해\n",
    "\n",
    "조경현 교수님의 새로운 방식은 \"모든 타임시리즈의 상태값을 전부 활용하자\"입니다.\n",
    "\n",
    "그리고 디코딩 방식도 조금 바꿔서, 단어 하나씩 입력되는 각각의 타임시리즈에 따라 동적으로 번역을 진행하는 것입니다.\n",
    "\n",
    "이렇게 함으로써 얻는 두 가지 큰 장점이 있습니다.\n",
    "\n",
    "### 첫째, 고정된 사이즈의 컨텍스트벡터를 사용하지 않습니다.\n",
    "\n",
    "다이나믹하게 각각의 스테이트별로 컨텍스트 벡터가 만들어지므로 사이즈에 구애받지 않게 되었습니다.\n",
    "\n",
    "### 둘째, 인코더의 모든 스테이트 중에서 집중해야 할 몇 개의 단어에만 집중할 수 있게 되었습니다.\n",
    "\n",
    "이게 바로 어텐션 메커니즘의 결과인데, 슬라이드로 간단히 설명드리겠습니다.\n",
    "\n",
    "우선 인코딩은 아래와 같이 동일합니다. RNN셀에 각각의 단어가 입력되었고 최종 상태값(컨텍스트벡터)도 출력된 상태입니다.\n",
    "\n",
    "![](https://i.ibb.co/MN3Gnjm/280.png)\n",
    "\n",
    "최종 상태값 하나만 활용하는 것이 아니라, 모든 스테이트의 상태값을 또 다른 밀집층,\n",
    "\n",
    "즉 어텐션 가중치를 구하기 위한 딥러닝 모델에 넣습니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://i.ibb.co/QHQ4xz9/282.png)\n",
    "\n",
    "<a href=\"https://app.box.com/s/sa0tn0l44j63ftgd0x3vvj2jerurhjo5/file/718298840376\">(슬라이드 참고)</a>\n",
    "\n",
    "위 과정을 통해 스타트시그널과 엔드시그널 사이의 값을 번역결과로 리턴하게 됩니다.\n",
    "\n",
    "어텐션 모델을 이해하기 위한 중요한 두 가지 개념은,\n",
    "\n",
    "### 1. 어텐션 가중치의 도입\n",
    "\n",
    "RNN 셀에서 얻은 최종 컨텍스트벡터에 집중하는 것이 아니라, 매 회차 인코더에서 출력되는 상태값을 확인하고, 이를 신경망에 넣어 각 단어의 스코어를 구하고, 이 스코어들을 소프트맥스로 돌려서 어텐션 가중치를 구합니다. 어텐션 가중치는 여러 개의 단어들 중 어느 단어에 가중치를 많이 줘야 하는지를 결정하고 이를 통해 스테이트별 컨텍스트벡터가 만들어집니다. 가중치가 적용된 컨텍스트벡터는 적절하게 어떤 한글단어가 나올 차례인지, 문맥상 어떤 의미의 번역을 해야 하는지를 알 수 있게 해 줍니다.\n",
    "\n",
    "### 2. 스테이트별로 컨텍스트벡터가 달라진다는 점\n",
    "\n",
    "하나의 함축된 최종컨텍스트벡터만 사용하는 것이 아닌, 단계적인 번역을 진행하고, 번역의 결과도 다시 어텐션 가중치를 구하는 데 사용되기 때문에, 문장 길이가 길어도 정보 소실이 거의 없다는 장점이 생깁니다.\n",
    "\n",
    "논문의 테스트에 따르면 seq2seq와 어텐션 메커니즘을 결합한 모델의 번역성능은 아래와 같다고 합니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://i.ibb.co/x1K6PrF/283.png)\n",
    "\n",
    "단어가 많든 적든 놀라운 퍼포먼스를 보이는 것을 확인할 수 있습니다.\n",
    "\n",
    "참고로 위에서 설명한 어텐션 기반 뉴럴머신 번역 튜토리얼은 텐서플로 공식 홈페이지에서도 공개하고 있으며, 아래 주소에서 튜토리얼을 확인하실 수 있습니다.\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/nmt_with_attention?hl=en\n",
    "\n",
    "이것으로 seq2seq와 attention 메커니즘의 설명을 마칩니다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 트랜스포머 : Attention is all you need\n",
    "\n",
    "트랜스포머는 seq2seq+attention에서 한 술 더 뜬 개념입니다. 어텐션 개념이 2014년 9월 개발되어 선풍적인 인기를 끌고 있는데, 트랜스포머는 무려 3년도 채 걸리지 않고 2017년 6월에 발표되었습니다.\n",
    "\n",
    "> 참고로 아카이브(arxiv.org)의 논문번호 앞 네자리는 \"연월\"을 나타냅니다.\n",
    "\n",
    "트랜스포머는 기존 인코더-디코더를 발전시킨 모델로, 가장 큰 차이점은 RNN을 전혀 사용하지 않는 방식입니다. 단어를 순차적으로 입력하는 방식이 아니기 때문에 학습속도도 빠른 반면 퍼포먼스가 더 좋아서 큰 관심을 끌었습니다.\n",
    "\n",
    "Attention is all you need 논문 안에는 공공연하게 트랜스포머의 성능을 자랑하는 표가 하나 들어있습니다.\n",
    "\n",
    "![](https://i.ibb.co/KL70pFd/285.png)\n",
    "\n",
    "트랜스포머는 사실 다소 복잡한 수학기법이 섞여 있는데, 개념만 간단히 이해하고 넘어가겠습니다.\n",
    "\n",
    "### 병렬화 - 트랜스포머 성능과 속도의 핵심원리\n",
    "\n",
    "트랜스포머는 시퀀스가 아니라 한 방에 처리합니다. RNN이 첫 번째 단어부터 순서대로 인코딩하는 반면 트랜스포머는 이 과정이 없습니다. 한 방에 처리합니다. **행렬곱**으로요.\n",
    "\n",
    "RNN 없이 트랜스포머는 어떻게 한 방에 병렬처리를 하면서 단어들의 어순이나 맥락을 파악할 수 있었을까요? 실마리는 바로 Positional Encoding으로 해결되었습니다.\n",
    "간단하게 설명하면 단어별 의미를 담은 벡터값에 위치정보를 나타내는 동일한 길이의 벡터를 더하는 기법을 사용했습니다.\n",
    "\n",
    "> 실제로 포지셔널 인코딩은 사인, 코사인함수를 주로 활용하며, 문장 길이에 따라 무한정 숫자가 커지는 방식이 아니라 상대적으로 그 다음 위치를 작은 범위 내에서 예측하고 처리할 수 있는 방식입니다.\n",
    "\n",
    "트랜스포머는 위 두 개의 과정, 워드임베딩과 포지셔널 인코딩 후에 self attention이라는 과정을 하나 더 거쳐각각의 단어벡터가 전부 단어의 의미, 위치정보와 문맥정보(모든 단어들이 미치는 영향) 세 가지를 전부 담게 됩니다.\n",
    "\n",
    "![](https://i.ibb.co/P9wVkJm/287.png)\n",
    "\n",
    "그리고 이 어텐션 레이어 하나하나를 또 전부 병렬처리합니다. (멀티헤드 어텐션)\n",
    "\n",
    "## Teacher-forcing을 통한 트랜스포머 학습\n",
    "\n",
    "마지막으로 트랜스포머 모델을 구성할 때, 학습과정이 궁금하시지 않나요? 트랜스포머 뿐만 아니라 인코더-디코더 모델도 훈련(학습)시에는 \"지도학습supervised-learning\"을 합니다. teacher-forcing이라는 학습방식을 사용하며, 우리말로는 \"교사강요\"라는 다소 촌스러운 용어를 쓰고 있습니다.\n",
    "\n",
    "교사 강요는, 비유하자면..\n",
    "\n",
    "\"I love you\"라는 문장을 \"난 널 사랑해\"로 번역하게 하고 싶은데, \"I\"를 넣은 시점의 결과가 \"난\"이 아니라 \"내가\"라는 결과라면? 이 오답이 다음 단어와 그 다음 단어를 예측하는 데에도 연쇄적으로 틀린 번역이 나올 수 있으므로, \"난\"이라는 정답을 오역 직후에 알려줘버리는 것입니다. 대규모 언어 데이터셋과 교사강요를 통해 트랜스포머 모델을 학습하게 됩니다.\n",
    "\n",
    "# 마지막으로 - 거인의 어깨에 올라타라\n",
    "\n",
    "우리는 항상 데이터가 부족합니다. 데이터가 부족하면 임베딩 학습이 충분히 이뤄지지 않고, 학습데이터에 충분한 단어가 제공되지 않으면 out-of-vocab 문제가 발생합니다. 그래서 우리는 이미 임베딩의 성능이 검증된 사전 학습된 임베딩을 사용하고, 적은 데이터로도 성능 좋은 자연어 처리 모델을 기대할 수 있게 됩니다.\n",
    "\n",
    "전이학습으로 모델을 학습할 경우 사용자는 전이된 레이어를 그대로 사용하거나, 전이된 레이어를 추가로 학습시킬 수도 있습니다. 전이된 레이어를 그대로 사용하는 경우 전이된 레이어의 일반성이 유지되고, 전이된 레이어를 추가로 함께 학습시켜서 사용자의 목적에 맞게 튜닝할 수도 있습니다. 전이학습을 활용하는 경우 수십회 정도의 적은 에포크로도 굉장히 높은 수준의 정확도를 보장할 수 있으므로, 언어모델 활용시에는 어느 정도 검증된 모델을 활용하는 것이 가성비 측면에서 좋습니다.\n",
    "\n",
    "오늘 수업은 여기서 마치겠습니다.\n",
    "\n",
    "감사합니다.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 참고 - GPT 이해하기\n",
    "\n",
    "<a href=\"https://app.box.com/s/sa0tn0l44j63ftgd0x3vvj2jerurhjo5/file/747581539543\">허민석의 GPT-1</a>\n",
    "\n",
    "<a href=\"https://app.box.com/s/sa0tn0l44j63ftgd0x3vvj2jerurhjo5/file/767676568260\">허민석의 GPT-2</a>\n",
    "\n",
    "<a href=\"https://app.box.com/s/sa0tn0l44j63ftgd0x3vvj2jerurhjo5/file/718298869176\">허민석의 GPT-3</a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 참고 - BERT 이해하기\n",
    "\n",
    "<a href=\"https://app.box.com/s/sa0tn0l44j63ftgd0x3vvj2jerurhjo5/file/808623190657\">허민석의 BERT PPT</a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}